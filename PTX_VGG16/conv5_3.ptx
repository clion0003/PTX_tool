.reg .u32 %r<30>;
.reg .u64 %rd<30>;
.reg .f32 %f<3500>;
.reg .pred %p<30>;

cvt.s32.u16 %r1, %tid.x;
cvt.s64.s32 %rd1, %r1;
mul.wide.s32 %rd2, %r1, 4;
ld.param.u64 %rd3, [_Z7conv5_3IfEvPT_PKS0_S3_S3__param_1];
add.u64 %rd4, %rd3, %rd2;
ld.param.u64 %rd5, [_Z7conv5_3IfEvPT_PKS0_S3_S3__param_2];
add.u64 %rd6, %rd5, %rd2;
ld.param.u64 %rd7, [_Z7conv5_3IfEvPT_PKS0_S3_S3__param_0];
add.u64 %rd8, %rd7, %rd2;
ld.param.u64 %rd9, [_Z7conv5_3IfEvPT_PKS0_S3_S3__param_3];

mov.s32 %r21, 128;
mov.s32 %r19, 256;
mov.s32 %r22, 16;
mov.u64 %rd12, %rd8;
mov.u64 %rd11, %rd6;
mov.u64 %rd10, %rd4;
mov.s32 %r23, 0;
$Lt_0:
mov.u64 %rd14, %rd9;
mov.u64 %rd16, %rd12;
mov.s32 %r20, 0;
$Lt_0_0:
ld.global.f32 %f250, [%rd14+0];
ld.global.f32 %f251, [%rd14+4];
ld.global.f32 %f252, [%rd14+8];
ld.global.f32 %f253, [%rd14+12];
mov.f32 %f200, %f250;
mov.f32 %f201, %f250;
mov.f32 %f202, %f251;
mov.f32 %f203, %f251;
mov.f32 %f204, %f252;
mov.f32 %f205, %f252;
mov.f32 %f206, %f253;
mov.f32 %f207, %f253;
ldc.global.f32 %f4,[%rd11+0], 0, 36;
ldc.global.f32 %f10, [%rd10+0], 0, 18;
ldc.global.f32 %f12, [%rd10+72], 3, 18;
ldc.global.f32 %f14, [%rd10+144], 6, 18;
add.u64 %rd15, %rd10, 1296;
add.u64 %rd13, %rd11, 18432;
mov.s32 %r18, 0;
$Lt_0_0_0:
ldc.global.f32 %f5,[%rd13], 0, 36;
ldc.global.f32 %f16, [%rd15+0], 0, 18;
ldc.global.f32 %f18, [%rd15+72], 3, 18;
ldc.global.f32 %f20, [%rd15+144], 6, 18;
fillw.f32 %f4;
shiftfull.f32 %f200, 20, %f10, 0, 2, 2;
shiftcol.f32 %f200, 21, %f10, 3, 2, 2;
shiftcol.f32 %f200, 22, %f10, 4, 2, 2;
shiftcol.f32 %f200, 23, %f10, 5, 2, 2;
shiftcol.f32 %f200, 24, %f10, 6, 2, 2;
shiftcol.f32 %f200, 25, %f10, 7, 2, 2;
shiftcol.f32 %f200, 26, %f10, 8, 2, 2;
shiftcol.f32 %f200, 27, %f10, 9, 2, 2;
shiftcol.f32 %f200, 28, %f10, 10, 2, 2;
shiftcol.f32 %f200, 29, %f10, 11, 2, 2;
shiftcol.f32 %f200, 30, %f10, 12, 2, 2;
shiftcol.f32 %f200, 31, %f10, 13, 2, 2;
shiftcol.f32 %f200, 32, %f10, 14, 2, 2;
shiftcol.f32 %f200, 33, %f10, 15, 2, 2;
shiftcol.f32 %f200, 34, %f10, 16, 2, 2;
shiftcol.f32 %f200, 35, %f10, 17, 2, 2;
add.u64 %rd15, %rd15, 1296;
add.u64 %rd13, %rd13, 18432;
ldc.global.f32 %f4,[%rd13], 0, 36;
ldc.global.f32 %f10, [%rd15+0], 0, 18;
ldc.global.f32 %f12, [%rd15+72], 3, 18;
ldc.global.f32 %f14, [%rd15+144], 6, 18;
fillw.f32 %f5;
shiftfull.f32 %f200, 20, %f16, 0, 2, 2;
shiftcol.f32 %f200, 21, %f16, 3, 2, 2;
shiftcol.f32 %f200, 22, %f16, 4, 2, 2;
shiftcol.f32 %f200, 23, %f16, 5, 2, 2;
shiftcol.f32 %f200, 24, %f16, 6, 2, 2;
shiftcol.f32 %f200, 25, %f16, 7, 2, 2;
shiftcol.f32 %f200, 26, %f16, 8, 2, 2;
shiftcol.f32 %f200, 27, %f16, 9, 2, 2;
shiftcol.f32 %f200, 28, %f16, 10, 2, 2;
shiftcol.f32 %f200, 29, %f16, 11, 2, 2;
shiftcol.f32 %f200, 30, %f16, 12, 2, 2;
shiftcol.f32 %f200, 31, %f16, 13, 2, 2;
shiftcol.f32 %f200, 32, %f16, 14, 2, 2;
shiftcol.f32 %f200, 33, %f16, 15, 2, 2;
shiftcol.f32 %f200, 34, %f16, 16, 2, 2;
shiftcol.f32 %f200, 35, %f16, 17, 2, 2;
add.u64 %rd15, %rd15, 1296;
add.u64 %rd13, %rd13, 18432;
add.s32 %r18, %r18, 1;
setp.ne.s32 %p1, %r18, %r19;
@%p1 bra $Lt_0_0_0;
stc.global.f32 [%rd16+0], %f200, 20, 16;
add.u64 %rd16, %rd16, 64;
add.u64 %rd16, %rd16, 960;
stc.global.f32 [%rd16+1024], %f202, 21, 15;
stc.global.f32 [%rd16+1084], %f203, 0, 1;
add.u64 %rd16, %rd16, 64;
add.u64 %rd16, %rd16, 960;
stc.global.f32 [%rd16+2048], %f204, 22, 14;
stc.global.f32 [%rd16+2104], %f205, 0, 2;
add.u64 %rd16, %rd16, 64;
add.u64 %rd16, %rd16, 960;
stc.global.f32 [%rd16+3072], %f206, 23, 13;
stc.global.f32 [%rd16+3124], %f207, 0, 3;
add.u64 %rd16, %rd16, 64;
add.u64 %rd16, %rd16, 960;
add.u64 %rd14, %rd14, 16;
add.s32 %r20, %r20, 1;
setp.ne.s32 %p2, %r20, %r21;
@%p2 bra $Lt_0_0;
add.u64 %rd12, %rd12, 64;
add.u64 %rd11, %rd11, 144;
add.u64 %rd10, %rd10, 72;
add.s32 %r23, %r23, 1;
setp.ne.s32 %p3, %r23, %r22;
@%p3 bra $Lt_0;
ret;
